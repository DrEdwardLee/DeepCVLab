{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Colab_Setup.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Create Basic Setup\n",
        "### 1. Installation\n",
        "* connect to own drive\n",
        "* create paths used throughout the notebook\n",
        "* get and install own repo\n",
        "* get and install waymo repo\n",
        "\n",
        "### 2. Data\n",
        "* transfer waymo dataset from gcs to gdrive\n",
        "* unpack \n",
        "* convert \n",
        "\n",
        "### 3. Training\n",
        "* training loop\n",
        "* visual assessment\n",
        "\n",
        "Remarks:\n",
        "* __linux_version paths should NOT be concatenated using e.g. os.path.join\n",
        "* data transfer: runtime cpu\n",
        "* waymo: tf is version 1.x\n",
        "* training: runtime gpu\n",
        "* tensorboard: enable 3rd party cookies in your browser"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 1. Installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "jEd97389k_4_"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "MOUNT\n",
        "'''\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "'''\n",
        "Create PATHS\n",
        "'''\n",
        "\n",
        "ROOT_DIR__linux_version = '/content/drive/My\\ Drive/Colab\\ Notebooks/DeepCV_Packages/'\n",
        "DATA_DIR__linux_version = ROOT_DIR__linux_version + 'data/'\n",
        "REPO_DIR__linux_version = ROOT_DIR__linux_version + 'DeepCVLab/'\n",
        "DEEPCVLAB_DIR__linux_version = REPO_DIR__linux_version + 'deepcvlab/'\n",
        "\n",
        "ARCHIVE_DEST_DIR__linux_version = '/content/drive/My\\ Drive/Colab\\ Notebooks/'                  # this should be a repo containing very few files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "'''\n",
        "GET OWN REPO\n",
        "'''\n",
        "\n",
        "%cd {ROOT_DIR__linux_version}\n",
        "!rm -rf {REPO_DIR__linux_version}\n",
        "!git clone https://github.com/pmcgrath249/DeepCVLab.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "YrDqTMowdI3a"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "INSTALL EVERYTHING\n",
        "'''\n",
        "\n",
        "# permanently change dir \n",
        "%cd {DEEPCVLAB_DIR__linux_version}\n",
        "\n",
        "# install waymo dataset utils in utils; https://github.com/waymo-research/waymo-open-dataset/blob/master/tutorial/tutorial.ipynb\n",
        "!cd utils && rm -rf waymo-od > /dev/null\n",
        "!cd utils && git clone https://github.com/waymo-research/waymo-open-dataset.git waymo-od\n",
        "!cd utils/waymo-od && git branch -a\n",
        "!cd utils/waymo-od && git checkout remotes/origin/r1.0\n",
        "!pip3 install --upgrade pip\n",
        "!pip3 install waymo-open-dataset\n",
        "\n",
        "# install requirements\n",
        "!cd {REPO_DIR__linux_version} && pip3 install -r requirements.txt\n",
        "\n",
        "# install own package\n",
        "!cd {REPO_DIR__linux_version} && python3 -m pip install ."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 2. DATA\n",
        "\n",
        "Data source: https://console.cloud.google.com/storage/browser/waymo_open_dataset_v_1_0_0\n",
        "\n",
        "### Transfer\n",
        "\n",
        "Help 1: https://medium.com/@philipplies/transferring-data-from-google-drive-to-google-cloud-storage-using-google-colab-96e088a8c041\n",
        "\n",
        "I had to change Help 1 because I was not able to find  the project_id nessecary for this approach\n",
        "\n",
        "Help 2: https://cloud.google.com/storage/docs/access-public-data?hl=de \n",
        "\n",
        "REMARK: No costs arise as the bucket is managed by waymo\n",
        "\n",
        "### Note\n",
        "\n",
        "* Use a CPU runtime for this section. It gives access to more disk storage w.r.t. the compute instance. Unpacking clutters the disk.\n",
        "* __linux_version paths cannot be concatenated using os.join because of spaces and escaping characters within the paths\n",
        "* Due to COLABxDRIVE issues, it is important to copy datasets to directories with little content.\n",
        "Otherwise it is not possible to extract files from the archives reliably.\n",
        "Moreover, I have had issues with moving archives -> iterative procedure\n",
        "https://research.google.com/colaboratory/faq.html#drive-timeout "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "'''\n",
        "AUTHENTICATE GCS\n",
        "'''\n",
        "\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "'''\n",
        "LIST DIR TO BE COPIED\n",
        "'''\n",
        "\n",
        "bucket_name = 'waymo_open_dataset_v_1_0_0'\n",
        "!gsutil ls -r gs://{bucket_name}/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "'''\n",
        "COPY GCS TO DRIVE AND \n",
        "UNPACK\n",
        "'''\n",
        "\n",
        "import os\n",
        "\n",
        "# naming\n",
        "bucket_name = 'waymo_open_dataset_v_1_0_0'\n",
        "training_bucket = os.path.join(bucket_name, 'training')\n",
        "\n",
        "for i in range(32):                                                                             # from ls above\n",
        "    dataset_name = 'training_000{}.tar'.format(i) if i < 10 else 'training_00{}.tar'.format(i)  # right amount of leading zeros\n",
        "    data_bucket = os.path.join(training_bucket, dataset_name)                 \n",
        "\n",
        "    print('start copying: ' + dataset_name)\n",
        "    !gsutil -m cp -r gs://{data_bucket}/ {ARCHIVE_DEST_DIR__linux_version}                          # copy multi-threaded and recursively\n",
        "\n",
        "    print('start unpacking: ' + dataset_name)\n",
        "    archive_full_path = ARCHIVE_DEST_DIR__linux_version + dataset_name\n",
        "    unpack_dest = DATA_DIR__linux_version + dataset_name[:-4] + '/'\n",
        "    !mkdir -p {unpack_dest}\n",
        "    !tar -xvf {archive_full_path} -C {unpack_dest}\n",
        "\n",
        "    print('deleting archive: ' + dataset_name)\n",
        "    !rm {archive_full_path}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "'''\n",
        "OFFLINE DATA CONVERSION\n",
        "'''\n",
        "\n",
        "%cd {REPO_DIR__linux_version}\n",
        "from deepcvlab.utils import Dense_U_Net_lidar_helper as utils\n",
        "utils.waymo_to_pytorch_offline()\n",
        "utils.distribute_data_into_train_val_test([0.6,0.2,0.2])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 3. Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "'''\n",
        "TRAINING WITH TENSORBOARD VISUALIZATION\n",
        "'''\n",
        "\n",
        "# import\n",
        "%cd {REPO_DIR__linux_version}\n",
        "from deepcvlab.utils.Dense_U_Net_lidar_helper import get_config\n",
        "from deepcvlab.agents.Dense_U_Net_lidar_Agent import Dense_U_Net_lidar_Agent as Dense_U_Agent\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "config = get_config()\n",
        "config.agent.max_epoch = 100\n",
        "\n",
        "# if first time training create summary dir before running for tensorboard to work\n",
        "Path(config.dir.summary).mkdir(exist_ok=True)\n",
        "\n",
        "# use tensorboard to visualize\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir {os.path.join(*config.dir.summary.split('/')[-2:])}\n",
        "\n",
        "# start training\n",
        "agent = Dense_U_Agent(config=config, torchvision_init=True)\n",
        "agent.run()\n",
        "agent.finalize()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "'''\n",
        "VISUALLY ASSESS DATA AFTER FORWARD PASS\n",
        "'''\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from deepcvlab.utils.Dense_U_Net_lidar_helper import get_config\n",
        "from deepcvlab.agents.Dense_U_Net_lidar_Agent import Dense_U_Net_lidar_Agent as Dense_U_Agent\n",
        "\n",
        "def visual_assessment(img, pred, gt):\n",
        "  \n",
        "    num_plots = gt.shape[0]\n",
        "    fig=plt.figure(figsize=(3*7,num_plots*7))\n",
        "    for i in range(num_plots):\n",
        "    \n",
        "        im = img[i].permute(1, 2, 0).detach().numpy().astype(np.uint8)\n",
        "        fig.add_subplot(num_plots, 3, i*3+1)   \n",
        "        plt.imshow(im)\n",
        "\n",
        "        p = pred[i].permute(1, 2, 0)[:,:,0].detach().numpy().astype(np.uint8)\n",
        "        fig.add_subplot(num_plots, 3, i*3+2)   \n",
        "        plt.imshow(p, cmap=plt.cm.gray)\n",
        "\n",
        "        g = gt[i].permute(1, 2, 0)[:,:,0].detach().numpy()\n",
        "        fig.add_subplot(num_plots, 3, i*3+3)   \n",
        "        plt.imshow(g, cmap=plt.cm.gray)\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "config = get_config()\n",
        "config.optimizer.mode = 'train'\n",
        "agent = Dense_U_Agent(torchvision_init=True)\n",
        "\n",
        "for image, lidar, _, ht_map in agent.data_loader.train_loader:\n",
        "            \n",
        "    if agent.cuda:\n",
        "        image = image.cuda()\n",
        "        lidar = lidar.cuda()\n",
        "\n",
        "    prediction = agent.model(image, lidar)\n",
        "\n",
        "    visual_assessment(image.cpu(), prediction.cpu(), ht_map)\n",
        "    continue"
      ]
    }
  ]
}